\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Assignment 1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Part 1: Binary classification and the perceptron}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Reading data}{1}}
\newlabel{sec:readdata}{{1.1.1}{1}}
\newlabel{fig:inputVectors}{{1.1.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of the input vectors with the target value visualized by colour.}}{1}}
\newlabel{fig:transformedInputVectors}{{1.1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of the transformed input vectors with the target value visualized by colour.}}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Perceptron training algorithm}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Perceptron decision boundary in the original data space at iterations \#1, \#3 and \#6 of online learning.}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{2}}
\newlabel{fig:origOL}{{3}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Perceptron decision boundary in the feature space of basis functions at iterations \#1, \#3 and \#6 of online learning.}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}}
\newlabel{fig:transOL}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Perceptron decision boundary in the original data space at iterations \#1, \#342 and \#685 of batch learning.}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}}
\newlabel{fig:origBA}{{5}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Perceptron decision boundary in the feature space of basis functions at iterations \#1, \#342 and \#685 of batch learning.}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}}
\newlabel{fig:transBA}{{6}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Plot of the decision boundary in the original data space found by the perceptron (green curve) together with labelled data points.}}{3}}
\newlabel{fig:perceptron}{{7}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Part 2: Linear basis function models for regression}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Experimental setup}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces An example of a true target function (thin green curve) from which the training data was generated, training set (without feature transformation) with $N=9$ (blue dots) and prediction of the fitted model ${\mathbf  w}^T{\mathbf  \Phi }(x)$ (blue curve). The basis functions are ${\mathbf  \Phi }(x) \rightarrow (1,x,x^2,x^3,...,x^d)^T$. (a) $d=2$ (b) $d=4$.}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Optimization: \emph  {LMS}-learning rule vs. closed form}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Model-complexity and model-selection}{5}}
